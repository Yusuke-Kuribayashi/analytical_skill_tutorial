{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ナイーブベイズ分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベイズの定理\n",
    "\n",
    "$P(\\boldsymbol{C} \\mid \\boldsymbol{x}) = \\frac{P(\\boldsymbol{x} \\mid \\boldsymbol{C}) \\cdot P(\\boldsymbol{C})}{P(\\boldsymbol{x})} $  \n",
    "\n",
    "今回求めたいのは、特徴ベクトルが得られたときにどちらに入るかの事後確率(=$P(C_n \\mid \\boldsymbol{x})$)  \n",
    "そのため、分母(周辺確率)はどのクラスの確率でも同じなため、比例式に変形可能  \n",
    "\n",
    "$P(\\boldsymbol{C} \\mid \\boldsymbol{x}) \\propto P(\\boldsymbol{x} \\mid \\boldsymbol{C}) \\cdot P(\\boldsymbol{C})$\n",
    "\n",
    "ナイーブ(単純)な仮定として、すべての特徴量が互いに独立であるとする：\n",
    "$P(\\boldsymbol{x} \\mid \\boldsymbol{C}) = \\prod_{i=1}^{n} P(x_i \\mid \\boldsymbol{C})$\n",
    "\n",
    "事後確率を変形  \n",
    "$P(\\boldsymbol{C} \\mid \\boldsymbol{x}) \\propto P(\\boldsymbol{C}) \\cdot \\prod_{i=1}^{n} P(x_i \\mid \\boldsymbol{C})$  \n",
    "\n",
    "それぞれの確率は、小さい値なため、logをとり小さい確率も考慮可能とする。  \n",
    "$\\log P(\\boldsymbol{C} \\mid \\boldsymbol{x}) \\propto \\log P(\\boldsymbol{C}) + \\sum_{i=1}^{n} \\log P(x_i \\mid \\boldsymbol{C})$\n",
    "\n",
    "最後に、ある特徴ベクトルが与えられたときにそれがスパムである確率とスパムでない確率を求め、大きい方のクラスに分類する。  \n",
    "$\\hat{C} = \\arg\\max_{C} ( \\log P(\\boldsymbol{C}) + \\sum_{i=1}^{n} \\log P(x_i \\mid \\boldsymbol{C}))$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "$\\boldsymbol{x} = (x_1, x_2, \\dots, x_n)$ : 説明変数(特徴ベクトル)  \n",
    "$\\boldsymbol{C}$ : 目的変数(スパムorスパムでない)  \n",
    "$P(\\boldsymbol{C} \\mid \\boldsymbol{x})$：事後確率  \n",
    "$P(\\boldsymbol{C})$：事前確率  \n",
    "$P(\\boldsymbol{x} \\mid \\boldsymbol{C})$：尤度  \n",
    "$P(\\boldsymbol{x})$：周辺確率  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スパムのデータを取得\n",
    "data = pd.read_csv('spambase_data.txt', header=None)\n",
    "\n",
    "# カラムがないため、カラム名を設定(spambase.namesを参照)\n",
    "columns = [\n",
    "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', \n",
    "    'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', \n",
    "    'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', \n",
    "    'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', \n",
    "    'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', \n",
    "    'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', \n",
    "    'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', \n",
    "    'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', \n",
    "    'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', \n",
    "    'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', \n",
    "    'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'spam'\n",
    "]\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数\n",
    "X = pd.DataFrame(data.iloc[:, :-1])\n",
    "# 目的変数(スパムかどうか)\n",
    "y = pd.Series(data.iloc[:, -1])\n",
    "# データをトレーニングセットとテストセットに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数をバイナリ化\n",
    "X_train, X_test = (X_train > 0.0).astype(int), (X_test > 0.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y):\n",
    "    prior = {}\n",
    "    likelihood = {}\n",
    "    # 事前確率と尤度を計算\n",
    "    for c in np.unique(y):\n",
    "        X_c = x[y == c]\n",
    "        # 事前確率の計算: P(C_m)\n",
    "        prior[c] = X_c.shape[0] / x.shape[0]\n",
    "        # 各特徴量の尤度関数: P(X_m|C_n)\n",
    "        # +1, +2は ラプラス平滑化のための措置(未知のデータでゼロ確率にならないように)\n",
    "        likelihood[c] = (X_c.sum(axis=0) + 1) / (len(X_c) + 2)\n",
    "\n",
    "    return prior, likelihood\n",
    "\n",
    "def predict(x, prior, likelihood):\n",
    "    pred = []\n",
    "    # あるサンプルデータについての予測を行う\n",
    "    for x0 in x:\n",
    "        # スパムと非スパムの事後確率: P(C_n|X_0, X_1, ..., X_m)\n",
    "        a = [0, 0]\n",
    "        for i in np.unique(y):\n",
    "            for j in range(len(x0)):\n",
    "                # 対数を取ることで計算の安定性を向上\n",
    "                a[i] += np.log(likelihood[i][j]) * x0[j]\n",
    "            # 事前確率を加える\n",
    "            a[i] += np.log(prior[i])\n",
    "        # 事後確率が最大のクラスに分類\n",
    "        pred.append(np.argmax(a))\n",
    "    return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8154180238870793\n",
      "Confusion Matrix:\n",
      "[[369 162]\n",
      " [  8 382]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Spam       0.98      0.69      0.81       531\n",
      "        Spam       0.70      0.98      0.82       390\n",
      "\n",
      "    accuracy                           0.82       921\n",
      "   macro avg       0.84      0.84      0.82       921\n",
      "weighted avg       0.86      0.82      0.81       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "prior, likelihood = fit(X_train.values, y_train.values)\n",
    "# モデルの予測\n",
    "pred = predict(X_test.values, prior, likelihood)\n",
    "# モデルの評価\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "# 混同行列と分類レポートの表示\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred, target_names=['Not Spam', 'Spam']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsb_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
